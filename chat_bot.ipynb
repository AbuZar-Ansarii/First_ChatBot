{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "Bb2-qa3VLIzg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import unicodedata\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvn4TQWGLUOU",
        "outputId": "fb36830c-de3a-472c-ee50-a0b10b32860d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "question  =[]\n",
        "answer = []\n",
        "with open(\"dialogs.txt\",'r') as f :\n",
        "    for line in f :\n",
        "        line  =  line.split('\\t')\n",
        "        question.append(line[0])\n",
        "        answer.append(line[1])\n",
        "print(len(question) == len(answer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guS8gjgGLwcs",
        "outputId": "fe3ba5d4-c238-48fc-adb4-7f7aacf61f44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hi, how are you doing?',\n",
              " \"i'm fine. how about yourself?\",\n",
              " \"i'm pretty good. thanks for asking.\",\n",
              " 'no problem. so how have you been?',\n",
              " \"i've been great. what about you?\"]"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEX7AWMhLy3d",
        "outputId": "94f41845-e139-4d0b-c5a4-06a642c66e2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"i'm fine. how about yourself?\\n\",\n",
              " \"i'm pretty good. thanks for asking.\\n\",\n",
              " 'no problem. so how have you been?\\n',\n",
              " \"i've been great. what about you?\\n\",\n",
              " \"i've been good. i'm in school right now.\\n\"]"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "answer[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "HqJv3k9SMfxo"
      },
      "outputs": [],
      "source": [
        "answer = [ i.replace(\"\\n\",\"\") for i in answer]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ggYjJdPiNi61",
        "outputId": "28d856d8-b5af-461f-f1a3-4327b72dd96b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi, how are you doing?</td>\n",
              "      <td>i'm fine. how about yourself?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i'm fine. how about yourself?</td>\n",
              "      <td>i'm pretty good. thanks for asking.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm pretty good. thanks for asking.</td>\n",
              "      <td>no problem. so how have you been?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no problem. so how have you been?</td>\n",
              "      <td>i've been great. what about you?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i've been great. what about you?</td>\n",
              "      <td>i've been good. i'm in school right now.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              question  \\\n",
              "0               hi, how are you doing?   \n",
              "1        i'm fine. how about yourself?   \n",
              "2  i'm pretty good. thanks for asking.   \n",
              "3    no problem. so how have you been?   \n",
              "4     i've been great. what about you?   \n",
              "\n",
              "                                     answer  \n",
              "0             i'm fine. how about yourself?  \n",
              "1       i'm pretty good. thanks for asking.  \n",
              "2         no problem. so how have you been?  \n",
              "3          i've been great. what about you?  \n",
              "4  i've been good. i'm in school right now.  "
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.DataFrame({\"question\" : question ,\"answer\":answer})\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "qGBbyIFkNleO"
      },
      "outputs": [],
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "fXy_RalnNoGd"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text = unicode_to_ascii(text.lower().strip())\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"\\r\", \"\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = re.sub(\"(\\\\W)\",\" \",text)\n",
        "    text = re.sub('\\S*\\d\\S*\\s*','', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Vq4mT8wyNtw_",
        "outputId": "f803922f-b6d1-40cc-cb46-36b98efc908e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hi, how are you doing?'"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"question\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tUnzmn_xNw6Z",
        "outputId": "19689d15-7fde-4c1d-ddd8-e90ab521b355"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hi how are you doing'"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[\"question\"] = data.question.apply(clean_text)\n",
        "data[\"question\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "E2T_Ct6hQOBW"
      },
      "outputs": [],
      "source": [
        "data[\"question\"] = [ i.replace(\"sos\",\"\") for i in question]\n",
        "data[\"answer\"]= [ i.replace(\"eos\",\"\") for i in answer]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "utrLGYuiOUMW",
        "outputId": "f42c5def-60f2-4d00-a66b-9bfbe1768b55"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi, how are you doing?</td>\n",
              "      <td>i'm fine. how about yourself?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i'm fine. how about yourself?</td>\n",
              "      <td>i'm pretty good. thanks for asking.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i'm pretty good. thanks for asking.</td>\n",
              "      <td>no problem. so how have you been?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>no problem. so how have you been?</td>\n",
              "      <td>i've been great. what about you?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i've been great. what about you?</td>\n",
              "      <td>i've been good. i'm in school right now.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3720</th>\n",
              "      <td>that's a good question. maybe it's not old age.</td>\n",
              "      <td>are you right-handed?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3721</th>\n",
              "      <td>are you right-handed?</td>\n",
              "      <td>yes. all my life.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3722</th>\n",
              "      <td>yes. all my life.</td>\n",
              "      <td>you're wearing out your right hand. stop using...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3723</th>\n",
              "      <td>you're wearing out your right hand. stop using...</td>\n",
              "      <td>but i do all my writing with my right hand.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3724</th>\n",
              "      <td>but i do all my writing with my right hand.</td>\n",
              "      <td>start typing instead. that way your left hand ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3725 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question  \\\n",
              "0                                hi, how are you doing?   \n",
              "1                         i'm fine. how about yourself?   \n",
              "2                   i'm pretty good. thanks for asking.   \n",
              "3                     no problem. so how have you been?   \n",
              "4                      i've been great. what about you?   \n",
              "...                                                 ...   \n",
              "3720    that's a good question. maybe it's not old age.   \n",
              "3721                              are you right-handed?   \n",
              "3722                                  yes. all my life.   \n",
              "3723  you're wearing out your right hand. stop using...   \n",
              "3724        but i do all my writing with my right hand.   \n",
              "\n",
              "                                                 answer  \n",
              "0                         i'm fine. how about yourself?  \n",
              "1                   i'm pretty good. thanks for asking.  \n",
              "2                     no problem. so how have you been?  \n",
              "3                      i've been great. what about you?  \n",
              "4              i've been good. i'm in school right now.  \n",
              "...                                                 ...  \n",
              "3720                              are you right-handed?  \n",
              "3721                                  yes. all my life.  \n",
              "3722  you're wearing out your right hand. stop using...  \n",
              "3723        but i do all my writing with my right hand.  \n",
              "3724  start typing instead. that way your left hand ...  \n",
              "\n",
              "[3725 rows x 2 columns]"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "okcL24EtObax"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, GRU, Reshape,Dropout,Input\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RdFY8H6HdII"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "Y_yMYxDnHEGn"
      },
      "outputs": [],
      "source": [
        "all_texts = list(data[\"question\"]) + list(data[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "PmC0NoWlJBgj"
      },
      "outputs": [],
      "source": [
        "# Initialize Tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "M5mzXlwQJJwu"
      },
      "outputs": [],
      "source": [
        "# Convert text to sequences\n",
        "input_sequences = tokenizer.texts_to_sequences(data[\"question\"])\n",
        "response_sequences = tokenizer.texts_to_sequences(data[\"answer\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "cV8y4Qe8JTUf"
      },
      "outputs": [],
      "source": [
        "# Padding sequences to ensure uniform input length\n",
        "max_len = max(max(len(seq) for seq in input_sequences), max(len(seq) for seq in response_sequences))\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_len, padding=\"post\")\n",
        "response_sequences = pad_sequences(response_sequences, maxlen=max_len, padding=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "Z19jHda3Jbw1"
      },
      "outputs": [],
      "source": [
        "# Vocabulary size (needed for embedding layer)\n",
        "vocab_size = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qMAEqvvJeyL",
        "outputId": "a0a093a3-0cf3-430f-fe31-3446ebf49d2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary Size: 2520\n",
            "Sample Input Sequence: [1522   36   14    2  174    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0]\n",
            "Sample Response Sequence: [ 31 614  36  33 562   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0]\n"
          ]
        }
      ],
      "source": [
        "print(\"Vocabulary Size:\", vocab_size)\n",
        "print(\"Sample Input Sequence:\", input_sequences[0])\n",
        "print(\"Sample Response Sequence:\", response_sequences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "3w3a1KF-Jjkf"
      },
      "outputs": [],
      "source": [
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_len,))\n",
        "encoder_embedding = Embedding(vocab_size, 256)(encoder_inputs)\n",
        "encoder_lstm = LSTM(512, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "MtoxujjXJ2TQ"
      },
      "outputs": [],
      "source": [
        "# Decoder\n",
        "decoder_inputs = Input(shape=(max_len,))\n",
        "decoder_embedding = Embedding(vocab_size, 256)(decoder_inputs)\n",
        "decoder_lstm = LSTM(512, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=[state_h, state_c])\n",
        "# dense\n",
        "decoder_dense = Dense(vocab_size, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "aCioaFPuJ9_h"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "TensorFlowTrainer.fit() got an unexpected keyword argument 'metrices'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[127], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Convert response_sequences to one-hot encoding\u001b[39;00m\n\u001b[0;32m      3\u001b[0m response_sequences_onehot \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mto_categorical(response_sequences, num_classes\u001b[38;5;241m=\u001b[39mvocab_size)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_sequences\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_sequences_onehot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmetrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\abu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\abu\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "\u001b[1;31mTypeError\u001b[0m: TensorFlowTrainer.fit() got an unexpected keyword argument 'metrices'"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "# Convert response_sequences to one-hot encoding\n",
        "response_sequences_onehot = tf.keras.utils.to_categorical(response_sequences, num_classes=vocab_size)\n",
        "\n",
        "model.fit([input_sequences, input_sequences], response_sequences_onehot, batch_size=32, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "Q7XGn6CBL6Mi",
        "outputId": "29c4cbfe-2a1b-4c97-bdc4-f31fee373ffd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "Bot: you it you going you just with but you          \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
            "Bot: the movie two in and the in  r          \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
            "Bot: you it you going you just with but you          \n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Bot: you it you going you just with but you          \n"
          ]
        }
      ],
      "source": [
        "def generate_response(user_input):\n",
        "    input_seq = tokenizer.texts_to_sequences([user_input])\n",
        "    input_seq = pad_sequences(input_seq, maxlen=max_len, padding=\"post\")\n",
        "\n",
        "    predicted_seq = model.predict([input_seq, input_seq])\n",
        "    predicted_words = [tokenizer.index_word.get(np.argmax(word), \"\") for word in predicted_seq[0]]\n",
        "\n",
        "    return \" \".join(predicted_words)\n",
        "\n",
        "# Chat with the bot\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        break\n",
        "    print(\"Bot:\", generate_response(user_input))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# hi, how are you doing?\ti'm fine. how about yourself?\n",
        "# 1\ti'm fine. how about yourself?\ti'm pretty good. thanks for asking.\n",
        "# 2\ti'm pretty good. thanks for asking.\tno problem. so how have you been?\n",
        "# 3\tno problem. so how have you been?\ti've been great. what about you?\n",
        "# 4\ti've been great. what about you?\ti've been good. i'm in school right now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYAqOYpKMAyd",
        "outputId": "9056a5e9-4ed1-4e2c-9423-9c99a4d6ce3d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# # Save model and tokenizer\n",
        "# model.save(\"seq2seq_chatbot.h5\")\n",
        "# import pickle\n",
        "# with open(\"tokenizer.pkl\", \"wb\") as f:\n",
        "#     pickle.dump(tokenizer, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4PS7HbCNOzc"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import load_model\n",
        "# import pickle\n",
        "\n",
        "# # Load model and tokenizer\n",
        "# model = load_model(\"seq2seq_chatbot.h5\")\n",
        "# with open(\"tokenizer.pkl\", \"rb\") as f:\n",
        "#     tokenizer = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "JOKER BOT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5GFtmQMLNuiO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Joke</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[me narrating a documentary about narrators] \"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Telling my daughter garlic is good for you. Go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>I've been going through a really rough period ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If I could have dinner with anyone, dead or al...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Two guys walk into a bar. The third guy ducks.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID                                               Joke\n",
              "0   1  [me narrating a documentary about narrators] \"...\n",
              "1   2  Telling my daughter garlic is good for you. Go...\n",
              "2   3  I've been going through a really rough period ...\n",
              "3   4  If I could have dinner with anyone, dead or al...\n",
              "4   5     Two guys walk into a bar. The third guy ducks."
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv(\"shortjokes.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 231657 entries, 0 to 231656\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   ID      231657 non-null  int64 \n",
            " 1   Joke    231657 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 3.5+ MB\n"
          ]
        }
      ],
      "source": [
        "data.shape\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data[\"Joke\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'a': 1,\n",
              " 'the': 2,\n",
              " 'i': 3,\n",
              " 'to': 4,\n",
              " 'you': 5,\n",
              " 'and': 6,\n",
              " 'in': 7,\n",
              " 'of': 8,\n",
              " 'my': 9,\n",
              " 'what': 10,\n",
              " 'is': 11,\n",
              " 'it': 12,\n",
              " 'do': 13,\n",
              " 'me': 14,\n",
              " 'on': 15,\n",
              " 'was': 16,\n",
              " 'for': 17,\n",
              " 'that': 18,\n",
              " 'with': 19,\n",
              " 'have': 20,\n",
              " 'why': 21,\n",
              " 'he': 22,\n",
              " 'your': 23,\n",
              " 'when': 24,\n",
              " 'did': 25,\n",
              " 'are': 26,\n",
              " 'like': 27,\n",
              " 'how': 28,\n",
              " 'they': 29,\n",
              " 'if': 30,\n",
              " 'so': 31,\n",
              " 'just': 32,\n",
              " 'at': 33,\n",
              " 'but': 34,\n",
              " 'an': 35,\n",
              " \"i'm\": 36,\n",
              " 'because': 37,\n",
              " 'one': 38,\n",
              " 'get': 39,\n",
              " 'his': 40,\n",
              " 'be': 41,\n",
              " 'out': 42,\n",
              " 'about': 43,\n",
              " \"don't\": 44,\n",
              " 'call': 45,\n",
              " 'up': 46,\n",
              " 'this': 47,\n",
              " \"it's\": 48,\n",
              " 'not': 49,\n",
              " 'her': 50,\n",
              " 'who': 51,\n",
              " 'can': 52,\n",
              " 'all': 53,\n",
              " 'no': 54,\n",
              " \"what's\": 55,\n",
              " 'say': 56,\n",
              " 'she': 57,\n",
              " 'know': 58,\n",
              " 'people': 59,\n",
              " 'does': 60,\n",
              " 'into': 61,\n",
              " 'from': 62,\n",
              " 'man': 63,\n",
              " 'there': 64,\n",
              " 'said': 65,\n",
              " 'got': 66,\n",
              " 'as': 67,\n",
              " 'we': 68,\n",
              " 'had': 69,\n",
              " 'between': 70,\n",
              " 'them': 71,\n",
              " 'joke': 72,\n",
              " 'time': 73,\n",
              " 'has': 74,\n",
              " 'go': 75,\n",
              " 'their': 76,\n",
              " 'by': 77,\n",
              " 'would': 78,\n",
              " 'two': 79,\n",
              " 'make': 80,\n",
              " \"can't\": 81,\n",
              " 'him': 82,\n",
              " 'take': 83,\n",
              " 'says': 84,\n",
              " 'other': 85,\n",
              " \"you're\": 86,\n",
              " 'only': 87,\n",
              " 'difference': 88,\n",
              " 'now': 89,\n",
              " 'wife': 90,\n",
              " 'never': 91,\n",
              " 'will': 92,\n",
              " 'day': 93,\n",
              " 'want': 94,\n",
              " 'guy': 95,\n",
              " 'think': 96,\n",
              " 'hear': 97,\n",
              " 'off': 98,\n",
              " 'then': 99,\n",
              " 'good': 100,\n",
              " 'really': 101,\n",
              " 'or': 102,\n",
              " 'see': 103,\n",
              " 'down': 104,\n",
              " 'many': 105,\n",
              " 'going': 106,\n",
              " 'bar': 107,\n",
              " 'new': 108,\n",
              " 'some': 109,\n",
              " 'were': 110,\n",
              " 'first': 111,\n",
              " 'always': 112,\n",
              " 'after': 113,\n",
              " 'black': 114,\n",
              " 'girl': 115,\n",
              " 'tell': 116,\n",
              " 'back': 117,\n",
              " 'over': 118,\n",
              " 'where': 119,\n",
              " 'too': 120,\n",
              " 'someone': 121,\n",
              " 'told': 122,\n",
              " 'sex': 123,\n",
              " 'been': 124,\n",
              " 'today': 125,\n",
              " 'more': 126,\n",
              " 'old': 127,\n",
              " 'asked': 128,\n",
              " \"i've\": 129,\n",
              " \"that's\": 130,\n",
              " \"didn't\": 131,\n",
              " 'dog': 132,\n",
              " 'last': 133,\n",
              " 'than': 134,\n",
              " '2': 135,\n",
              " 'should': 136,\n",
              " 'women': 137,\n",
              " 'woman': 138,\n",
              " 'knock': 139,\n",
              " 'friend': 140,\n",
              " 'love': 141,\n",
              " 'ever': 142,\n",
              " 'way': 143,\n",
              " 'life': 144,\n",
              " 'called': 145,\n",
              " 'walks': 146,\n",
              " 'put': 147,\n",
              " 'could': 148,\n",
              " \"they're\": 149,\n",
              " 'before': 150,\n",
              " \"doesn't\": 151,\n",
              " 'every': 152,\n",
              " 'car': 153,\n",
              " 'well': 154,\n",
              " 'thing': 155,\n",
              " \"i'll\": 156,\n",
              " 'right': 157,\n",
              " 'best': 158,\n",
              " 'girlfriend': 159,\n",
              " 'much': 160,\n",
              " 'being': 161,\n",
              " 'need': 162,\n",
              " \"he's\": 163,\n",
              " 'jokes': 164,\n",
              " 'favorite': 165,\n",
              " 'dad': 166,\n",
              " 'little': 167,\n",
              " 'look': 168,\n",
              " 'bad': 169,\n",
              " 'eat': 170,\n",
              " 'work': 171,\n",
              " 'year': 172,\n",
              " 'night': 173,\n",
              " '1': 174,\n",
              " 'name': 175,\n",
              " 'still': 176,\n",
              " 'come': 177,\n",
              " 'made': 178,\n",
              " '3': 179,\n",
              " 'here': 180,\n",
              " 'shit': 181,\n",
              " 'give': 182,\n",
              " 'went': 183,\n",
              " 'doctor': 184,\n",
              " 'any': 185,\n",
              " 'baby': 186,\n",
              " 'stop': 187,\n",
              " 'find': 188,\n",
              " 'its': 189,\n",
              " 'most': 190,\n",
              " 'long': 191,\n",
              " 'kids': 192,\n",
              " 'both': 193,\n",
              " 'around': 194,\n",
              " 'q': 195,\n",
              " 'am': 196,\n",
              " 'getting': 197,\n",
              " 'guys': 198,\n",
              " 'change': 199,\n",
              " 'years': 200,\n",
              " 'once': 201,\n",
              " 'house': 202,\n",
              " 'men': 203,\n",
              " 'while': 204,\n",
              " 'having': 205,\n",
              " 'heard': 206,\n",
              " \"there's\": 207,\n",
              " 'walk': 208,\n",
              " 'white': 209,\n",
              " 'use': 210,\n",
              " 'even': 211,\n",
              " 'world': 212,\n",
              " 'person': 213,\n",
              " 'sorry': 214,\n",
              " 'dead': 215,\n",
              " 'son': 216,\n",
              " 'oh': 217,\n",
              " 'something': 218,\n",
              " 'hey': 219,\n",
              " 'common': 220,\n",
              " 'saw': 221,\n",
              " 'thought': 222,\n",
              " 'mom': 223,\n",
              " 'home': 224,\n",
              " 'light': 225,\n",
              " 'gay': 226,\n",
              " 'job': 227,\n",
              " 'which': 228,\n",
              " 'keep': 229,\n",
              " 'hate': 230,\n",
              " 'everyone': 231,\n",
              " 'god': 232,\n",
              " 'cross': 233,\n",
              " 'gets': 234,\n",
              " 'big': 235,\n",
              " \"i'd\": 236,\n",
              " 'u': 237,\n",
              " 'great': 238,\n",
              " 'sure': 239,\n",
              " '10': 240,\n",
              " 'phone': 241,\n",
              " 'hard': 242,\n",
              " 'those': 243,\n",
              " 'used': 244,\n",
              " 'wanted': 245,\n",
              " '5': 246,\n",
              " 'next': 247,\n",
              " 'very': 248,\n",
              " 'lot': 249,\n",
              " 'away': 250,\n",
              " 'face': 251,\n",
              " 'found': 252,\n",
              " 'better': 253,\n",
              " 'let': 254,\n",
              " 'trump': 255,\n",
              " 'goes': 256,\n",
              " 'our': 257,\n",
              " 'left': 258,\n",
              " \"who's\": 259,\n",
              " 'nothing': 260,\n",
              " 'asks': 261,\n",
              " 'please': 262,\n",
              " 'came': 263,\n",
              " 'ask': 264,\n",
              " 'three': 265,\n",
              " 'wrong': 266,\n",
              " 'food': 267,\n",
              " 'things': 268,\n",
              " 'fat': 269,\n",
              " 'kid': 270,\n",
              " 'boy': 271,\n",
              " 'yes': 272,\n",
              " 'head': 273,\n",
              " '4': 274,\n",
              " 'feel': 275,\n",
              " \"couldn't\": 276,\n",
              " 'same': 277,\n",
              " 'friends': 278,\n",
              " 'cat': 279,\n",
              " 'water': 280,\n",
              " 'kind': 281,\n",
              " 'money': 282,\n",
              " 'again': 283,\n",
              " 'chicken': 284,\n",
              " 'us': 285,\n",
              " 'drink': 286,\n",
              " 'myself': 287,\n",
              " 'doing': 288,\n",
              " 'until': 289,\n",
              " \"she's\": 290,\n",
              " 'through': 291,\n",
              " 'play': 292,\n",
              " 'school': 293,\n",
              " 'pretty': 294,\n",
              " 'fuck': 295,\n",
              " 'trying': 296,\n",
              " 'makes': 297,\n",
              " 'door': 298,\n",
              " 'part': 299,\n",
              " 'hand': 300,\n",
              " 'mean': 301,\n",
              " 'girls': 302,\n",
              " 'start': 303,\n",
              " 'jesus': 304,\n",
              " 'without': 305,\n",
              " 'another': 306,\n",
              " 'funny': 307,\n",
              " 'dick': 308,\n",
              " 'anything': 309,\n",
              " 'looks': 310,\n",
              " 'hot': 311,\n",
              " 'probably': 312,\n",
              " 'fish': 313,\n",
              " '9': 314,\n",
              " 'run': 315,\n",
              " 'date': 316,\n",
              " 'gonna': 317,\n",
              " \"isn't\": 318,\n",
              " 'guess': 319,\n",
              " 'watch': 320,\n",
              " 'bed': 321,\n",
              " 'looking': 322,\n",
              " 'show': 323,\n",
              " 'room': 324,\n",
              " 'road': 325,\n",
              " 'christmas': 326,\n",
              " 'ok': 327,\n",
              " 'morning': 328,\n",
              " 'word': 329,\n",
              " 'red': 330,\n",
              " 'buy': 331,\n",
              " 'fucking': 332,\n",
              " 'lost': 333,\n",
              " 'help': 334,\n",
              " 'died': 335,\n",
              " 'enough': 336,\n",
              " 'pizza': 337,\n",
              " 'die': 338,\n",
              " 'own': 339,\n",
              " '6': 340,\n",
              " 'kill': 341,\n",
              " 'making': 342,\n",
              " 'high': 343,\n",
              " \"won't\": 344,\n",
              " 'tried': 345,\n",
              " 'movie': 346,\n",
              " 'wear': 347,\n",
              " 'coffee': 348,\n",
              " 'real': 349,\n",
              " 'hit': 350,\n",
              " 'police': 351,\n",
              " 'end': 352,\n",
              " 'r': 353,\n",
              " 'eating': 354,\n",
              " \"wasn't\": 355,\n",
              " 'comes': 356,\n",
              " 'ass': 357,\n",
              " 'teacher': 358,\n",
              " 'bulb': 359,\n",
              " 'bartender': 360,\n",
              " 'talk': 361,\n",
              " 'everything': 362,\n",
              " 'remember': 363,\n",
              " 'family': 364,\n",
              " 'anyone': 365,\n",
              " 'legs': 366,\n",
              " 'leave': 367,\n",
              " '7': 368,\n",
              " 'half': 369,\n",
              " 'lightbulb': 370,\n",
              " 'read': 371,\n",
              " 'wait': 372,\n",
              " 'these': 373,\n",
              " 'try': 374,\n",
              " 'live': 375,\n",
              " 'game': 376,\n",
              " 'full': 377,\n",
              " 'actually': 378,\n",
              " 'mexican': 379,\n",
              " 'free': 380,\n",
              " 'took': 381,\n",
              " 'saying': 382,\n",
              " 'party': 383,\n",
              " 'nice': 384,\n",
              " 'mother': 385,\n",
              " 'screw': 386,\n",
              " 'yeah': 387,\n",
              " 'store': 388,\n",
              " 'believe': 389,\n",
              " 'talking': 390,\n",
              " 'side': 391,\n",
              " 'turns': 392,\n",
              " 'days': 393,\n",
              " 'donald': 394,\n",
              " 'turn': 395,\n",
              " 'body': 396,\n",
              " 'horse': 397,\n",
              " 'book': 398,\n",
              " 'second': 399,\n",
              " 'whats': 400,\n",
              " 'seen': 401,\n",
              " 'beer': 402,\n",
              " 'blonde': 403,\n",
              " 'eyes': 404,\n",
              " 'wanna': 405,\n",
              " 'already': 406,\n",
              " 'must': 407,\n",
              " 'hands': 408,\n",
              " 'under': 409,\n",
              " 'hair': 410,\n",
              " 'happy': 411,\n",
              " 'number': 412,\n",
              " 'times': 413,\n",
              " 'hell': 414,\n",
              " 'father': 415,\n",
              " 'facebook': 416,\n",
              " 'open': 417,\n",
              " 'worst': 418,\n",
              " \"'\": 419,\n",
              " 'place': 420,\n",
              " 'gave': 421,\n",
              " 'sleep': 422,\n",
              " 'cow': 423,\n",
              " 'apparently': 424,\n",
              " 'reddit': 425,\n",
              " 'fire': 426,\n",
              " 'fun': 427,\n",
              " 'front': 428,\n",
              " 'least': 429,\n",
              " 'husband': 430,\n",
              " 'pants': 431,\n",
              " 'coming': 432,\n",
              " 'line': 433,\n",
              " 'blind': 434,\n",
              " 'stand': 435,\n",
              " 'parents': 436,\n",
              " 'penis': 437,\n",
              " 'news': 438,\n",
              " 'tree': 439,\n",
              " \"we're\": 440,\n",
              " 'instead': 441,\n",
              " \"you've\": 442,\n",
              " '8': 443,\n",
              " 'toilet': 444,\n",
              " 'drive': 445,\n",
              " 'small': 446,\n",
              " 'cool': 447,\n",
              " 'may': 448,\n",
              " 'boss': 449,\n",
              " 'walking': 450,\n",
              " 'cop': 451,\n",
              " 'bill': 452,\n",
              " 'also': 453,\n",
              " 'during': 454,\n",
              " 'bought': 455,\n",
              " 'children': 456,\n",
              " 'started': 457,\n",
              " 'child': 458,\n",
              " 'married': 459,\n",
              " 'mouth': 460,\n",
              " 'wants': 461,\n",
              " 'each': 462,\n",
              " 'twitter': 463,\n",
              " 'week': 464,\n",
              " 'named': 465,\n",
              " 'cause': 466,\n",
              " 'wish': 467,\n",
              " 'whole': 468,\n",
              " 'replies': 469,\n",
              " 'wearing': 470,\n",
              " \"wouldn't\": 471,\n",
              " 'm': 472,\n",
              " 'drunk': 473,\n",
              " 'racist': 474,\n",
              " 'thanks': 475,\n",
              " 'sometimes': 476,\n",
              " 'takes': 477,\n",
              " 'problem': 478,\n",
              " 'pay': 479,\n",
              " 'fall': 480,\n",
              " 'cut': 481,\n",
              " 'stupid': 482,\n",
              " 'might': 483,\n",
              " 'eye': 484,\n",
              " 'words': 485,\n",
              " 'four': 486,\n",
              " 'pick': 487,\n",
              " 'together': 488,\n",
              " 'sir': 489,\n",
              " 'ice': 490,\n",
              " 'yesterday': 491,\n",
              " 'inside': 492,\n",
              " 'minutes': 493,\n",
              " 'bear': 494,\n",
              " 'cheese': 495,\n",
              " 'hitler': 496,\n",
              " 'american': 497,\n",
              " 'cold': 498,\n",
              " '20': 499,\n",
              " 'replied': 500,\n",
              " 'chinese': 501,\n",
              " 'taking': 502,\n",
              " 'internet': 503,\n",
              " 'paper': 504,\n",
              " \"aren't\": 505,\n",
              " 'fell': 506,\n",
              " 'president': 507,\n",
              " 'outside': 508,\n",
              " 'hope': 509,\n",
              " 'idea': 510,\n",
              " 'lady': 511,\n",
              " 'jewish': 512,\n",
              " 'yo': 513,\n",
              " 'walked': 514,\n",
              " 'nuts': 515,\n",
              " 'running': 516,\n",
              " 'playing': 517,\n",
              " 'dinner': 518,\n",
              " 'answer': 519,\n",
              " 'wall': 520,\n",
              " 'watching': 521,\n",
              " 't': 522,\n",
              " 'behind': 523,\n",
              " 'd': 524,\n",
              " 'bus': 525,\n",
              " 'understand': 526,\n",
              " 'santa': 527,\n",
              " 'mind': 528,\n",
              " 'type': 529,\n",
              " 'post': 530,\n",
              " 'computer': 531,\n",
              " 'means': 532,\n",
              " 'else': 533,\n",
              " 'yet': 534,\n",
              " 'done': 535,\n",
              " 'damn': 536,\n",
              " 'ex': 537,\n",
              " 'box': 538,\n",
              " 'throw': 539,\n",
              " 'finally': 540,\n",
              " 'none': 541,\n",
              " 'later': 542,\n",
              " 'bathroom': 543,\n",
              " \"you'll\": 544,\n",
              " 'happened': 545,\n",
              " 'dogs': 546,\n",
              " 'street': 547,\n",
              " 'since': 548,\n",
              " 'fight': 549,\n",
              " 'america': 550,\n",
              " 'sitting': 551,\n",
              " 'five': 552,\n",
              " 'such': 553,\n",
              " 'bring': 554,\n",
              " 'ate': 555,\n",
              " 'apple': 556,\n",
              " 'hold': 557,\n",
              " 'using': 558,\n",
              " 'group': 559,\n",
              " 'hours': 560,\n",
              " 'dark': 561,\n",
              " \"haven't\": 562,\n",
              " '11': 563,\n",
              " 'daughter': 564,\n",
              " 'top': 565,\n",
              " '50': 566,\n",
              " 'yourself': 567,\n",
              " 'mine': 568,\n",
              " 'question': 569,\n",
              " 'afraid': 570,\n",
              " 'driving': 571,\n",
              " 'few': 572,\n",
              " '12': 573,\n",
              " 'thinking': 574,\n",
              " 'telling': 575,\n",
              " 'birthday': 576,\n",
              " 'balls': 577,\n",
              " 'chuck': 578,\n",
              " 'song': 579,\n",
              " 'short': 580,\n",
              " 'club': 581,\n",
              " 'turned': 582,\n",
              " 'favourite': 583,\n",
              " 'fly': 584,\n",
              " 'death': 585,\n",
              " 'wonder': 586,\n",
              " 'priest': 587,\n",
              " 'hole': 588,\n",
              " 'happens': 589,\n",
              " 'nobody': 590,\n",
              " \"let's\": 591,\n",
              " 'working': 592,\n",
              " 'e': 593,\n",
              " 'class': 594,\n",
              " 'pregnant': 595,\n",
              " 'music': 596,\n",
              " 'maybe': 597,\n",
              " 'office': 598,\n",
              " 'milk': 599,\n",
              " 'restaurant': 600,\n",
              " 'bit': 601,\n",
              " 'met': 602,\n",
              " 'middle': 603,\n",
              " '100': 604,\n",
              " 'shot': 605,\n",
              " 'become': 606,\n",
              " 'tv': 607,\n",
              " 'b': 608,\n",
              " 'amp': 609,\n",
              " 'table': 610,\n",
              " 'bag': 611,\n",
              " 'edit': 612,\n",
              " 'single': 613,\n",
              " 's': 614,\n",
              " 'beat': 615,\n",
              " 'french': 616,\n",
              " 'drinking': 617,\n",
              " 'matter': 618,\n",
              " 'shoes': 619,\n",
              " 'elephant': 620,\n",
              " 'green': 621,\n",
              " 'broke': 622,\n",
              " 'thank': 623,\n",
              " 'blood': 624,\n",
              " 'sign': 625,\n",
              " 'star': 626,\n",
              " 'late': 627,\n",
              " 'break': 628,\n",
              " 'feet': 629,\n",
              " 'stuck': 630,\n",
              " 'im': 631,\n",
              " 'sick': 632,\n",
              " 'c': 633,\n",
              " 'order': 634,\n",
              " 'rest': 635,\n",
              " 'plane': 636,\n",
              " 'math': 637,\n",
              " 'picture': 638,\n",
              " 'six': 639,\n",
              " 'blue': 640,\n",
              " 'sound': 641,\n",
              " 'jew': 642,\n",
              " 'fast': 643,\n",
              " 'air': 644,\n",
              " 'either': 645,\n",
              " 'story': 646,\n",
              " 'bird': 647,\n",
              " 'sister': 648,\n",
              " 'window': 649,\n",
              " 'space': 650,\n",
              " 'laugh': 651,\n",
              " 'german': 652,\n",
              " 'tonight': 653,\n",
              " 'piece': 654,\n",
              " 'babies': 655,\n",
              " 'caught': 656,\n",
              " 'ago': 657,\n",
              " 'business': 658,\n",
              " 'okay': 659,\n",
              " 'knows': 660,\n",
              " 'killed': 661,\n",
              " 'nsfw': 662,\n",
              " 'ugly': 663,\n",
              " 'ten': 664,\n",
              " 'gun': 665,\n",
              " 'brown': 666,\n",
              " 'ones': 667,\n",
              " 'tired': 668,\n",
              " 'sit': 669,\n",
              " 'leg': 670,\n",
              " 'decided': 671,\n",
              " 'norris': 672,\n",
              " 'ball': 673,\n",
              " 'com': 674,\n",
              " 'recently': 675,\n",
              " 'far': 676,\n",
              " 'porn': 677,\n",
              " 'win': 678,\n",
              " 'set': 679,\n",
              " '30': 680,\n",
              " 'check': 681,\n",
              " 'arms': 682,\n",
              " 'human': 683,\n",
              " 'wow': 684,\n",
              " 'move': 685,\n",
              " 'close': 686,\n",
              " 'lose': 687,\n",
              " 'weird': 688,\n",
              " 'marriage': 689,\n",
              " 'batman': 690,\n",
              " 'bread': 691,\n",
              " 'bet': 692,\n",
              " 'though': 693,\n",
              " 'large': 694,\n",
              " 'worse': 695,\n",
              " 'case': 696,\n",
              " 'country': 697,\n",
              " 'hillary': 698,\n",
              " 'bunch': 699,\n",
              " 'accidentally': 700,\n",
              " 'giving': 701,\n",
              " 'dude': 702,\n",
              " 'starts': 703,\n",
              " 'clinton': 704,\n",
              " 'knew': 705,\n",
              " 'tells': 706,\n",
              " 'smell': 707,\n",
              " 'asian': 708,\n",
              " 'taste': 709,\n",
              " 'sad': 710,\n",
              " 'likes': 711,\n",
              " 'egg': 712,\n",
              " 'different': 713,\n",
              " 'dating': 714,\n",
              " 'stick': 715,\n",
              " 'hi': 716,\n",
              " 'born': 717,\n",
              " 'fine': 718,\n",
              " 'ran': 719,\n",
              " 'test': 720,\n",
              " 'less': 721,\n",
              " 'floor': 722,\n",
              " 'stay': 723,\n",
              " 'care': 724,\n",
              " 'forget': 725,\n",
              " 'pirate': 726,\n",
              " 'bank': 727,\n",
              " 'dont': 728,\n",
              " 'crazy': 729,\n",
              " 'young': 730,\n",
              " 'female': 731,\n",
              " 'brother': 732,\n",
              " 'reason': 733,\n",
              " 'john': 734,\n",
              " 'text': 735,\n",
              " 'shower': 736,\n",
              " 'boyfriend': 737,\n",
              " 'heart': 738,\n",
              " 'mad': 739,\n",
              " 'keeps': 740,\n",
              " 'invented': 741,\n",
              " 'duck': 742,\n",
              " 'glass': 743,\n",
              " 'months': 744,\n",
              " 'poor': 745,\n",
              " 'church': 746,\n",
              " 'whenever': 747,\n",
              " 'course': 748,\n",
              " 'terrible': 749,\n",
              " 'catch': 750,\n",
              " 'alone': 751,\n",
              " 'band': 752,\n",
              " 'credit': 753,\n",
              " 'sounds': 754,\n",
              " 'cream': 755,\n",
              " 'shop': 756,\n",
              " 'self': 757,\n",
              " 'stuff': 758,\n",
              " 'hour': 759,\n",
              " 'park': 760,\n",
              " 'blow': 761,\n",
              " 'against': 762,\n",
              " 'wedding': 763,\n",
              " 'team': 764,\n",
              " 'earth': 765,\n",
              " 'dirty': 766,\n",
              " 'jews': 767,\n",
              " 'cancer': 768,\n",
              " 'past': 769,\n",
              " 'point': 770,\n",
              " 'meat': 771,\n",
              " 'cats': 772,\n",
              " 'won': 773,\n",
              " 'almost': 774,\n",
              " 'letter': 775,\n",
              " 'idiot': 776,\n",
              " 'rock': 777,\n",
              " 'himself': 778,\n",
              " 'nose': 779,\n",
              " 'gas': 780,\n",
              " 'king': 781,\n",
              " 'ground': 782,\n",
              " 'worry': 783,\n",
              " 'michael': 784,\n",
              " 'meet': 785,\n",
              " 'couple': 786,\n",
              " 'wine': 787,\n",
              " 'clothes': 788,\n",
              " 'looked': 789,\n",
              " 'gives': 790,\n",
              " 'fit': 791,\n",
              " 'pull': 792,\n",
              " 'calling': 793,\n",
              " 'naked': 794,\n",
              " 'teeth': 795,\n",
              " 'super': 796,\n",
              " 'kept': 797,\n",
              " 'anymore': 798,\n",
              " 'machine': 799,\n",
              " 'sandwich': 800,\n",
              " 'animal': 801,\n",
              " 'drug': 802,\n",
              " 'o': 803,\n",
              " 'gym': 804,\n",
              " 'sea': 805,\n",
              " 'count': 806,\n",
              " 'clean': 807,\n",
              " 'works': 808,\n",
              " 'straight': 809,\n",
              " 'english': 810,\n",
              " 'asking': 811,\n",
              " 'beautiful': 812,\n",
              " 'age': 813,\n",
              " 'needs': 814,\n",
              " 'race': 815,\n",
              " 'thinks': 816,\n",
              " 'prostitute': 817,\n",
              " 'send': 818,\n",
              " 'prison': 819,\n",
              " 'living': 820,\n",
              " 'drop': 821,\n",
              " 'write': 822,\n",
              " 'true': 823,\n",
              " 'easy': 824,\n",
              " 'soon': 825,\n",
              " 'suicide': 826,\n",
              " 'million': 827,\n",
              " \"they'll\": 828,\n",
              " 'w': 829,\n",
              " 'period': 830,\n",
              " 'judge': 831,\n",
              " 'arrested': 832,\n",
              " 'miss': 833,\n",
              " 'zoo': 834,\n",
              " 'dollars': 835,\n",
              " 'shirt': 836,\n",
              " 'step': 837,\n",
              " 'relationship': 838,\n",
              " 'forgot': 839,\n",
              " 'college': 840,\n",
              " 'entire': 841,\n",
              " 'tip': 842,\n",
              " 'able': 843,\n",
              " 'fact': 844,\n",
              " 'officer': 845,\n",
              " 'standing': 846,\n",
              " 'iphone': 847,\n",
              " 'pussy': 848,\n",
              " 'butt': 849,\n",
              " 'hello': 850,\n",
              " 'history': 851,\n",
              " 'reading': 852,\n",
              " 'snow': 853,\n",
              " 'cake': 854,\n",
              " 'dollar': 855,\n",
              " 'tomorrow': 856,\n",
              " 'moon': 857,\n",
              " \"shouldn't\": 858,\n",
              " 'runs': 859,\n",
              " 'funeral': 860,\n",
              " 'dear': 861,\n",
              " 'mexicans': 862,\n",
              " 'waiter': 863,\n",
              " 'seconds': 864,\n",
              " 'card': 865,\n",
              " 'ring': 866,\n",
              " 'russian': 867,\n",
              " 'unless': 868,\n",
              " 'across': 869,\n",
              " 'deer': 870,\n",
              " 'drugs': 871,\n",
              " 'breakfast': 872,\n",
              " 'lesbian': 873,\n",
              " 'longer': 874,\n",
              " 'http': 875,\n",
              " 'finger': 876,\n",
              " 'halloween': 877,\n",
              " 'war': 878,\n",
              " 'ladies': 879,\n",
              " 'student': 880,\n",
              " 'except': 881,\n",
              " 'cops': 882,\n",
              " 'lawyer': 883,\n",
              " 'ghost': 884,\n",
              " 'foot': 885,\n",
              " 'law': 886,\n",
              " 'calls': 887,\n",
              " 'honey': 888,\n",
              " 'feeling': 889,\n",
              " 'jack': 890,\n",
              " 'mama': 891,\n",
              " 'realized': 892,\n",
              " 'seven': 893,\n",
              " 'homeless': 894,\n",
              " 'fired': 895,\n",
              " 'p': 896,\n",
              " 'irish': 897,\n",
              " '000': 898,\n",
              " 'angry': 899,\n",
              " 'cry': 900,\n",
              " 'finish': 901,\n",
              " 'obama': 902,\n",
              " 'problems': 903,\n",
              " 'lol': 904,\n",
              " 'hide': 905,\n",
              " 'driver': 906,\n",
              " 'dance': 907,\n",
              " \"you'd\": 908,\n",
              " 'eggs': 909,\n",
              " '15': 910,\n",
              " 'x': 911,\n",
              " 'ear': 912,\n",
              " 'asshole': 913,\n",
              " 'sees': 914,\n",
              " 'orange': 915,\n",
              " 'fruit': 916,\n",
              " 'hang': 917,\n",
              " 'male': 918,\n",
              " 'ur': 919,\n",
              " 'gone': 920,\n",
              " 'trust': 921,\n",
              " 'local': 922,\n",
              " 'smart': 923,\n",
              " 'putting': 924,\n",
              " 'field': 925,\n",
              " 'google': 926,\n",
              " 'bottle': 927,\n",
              " 'f': 928,\n",
              " 'public': 929,\n",
              " 'fingers': 930,\n",
              " 'alcohol': 931,\n",
              " 'midget': 932,\n",
              " 'kitchen': 933,\n",
              " 'crying': 934,\n",
              " 'suck': 935,\n",
              " 'month': 936,\n",
              " 'broken': 937,\n",
              " 'bitch': 938,\n",
              " 'taken': 939,\n",
              " 'huge': 940,\n",
              " 'spend': 941,\n",
              " 'twice': 942,\n",
              " 'dyslexic': 943,\n",
              " 'brain': 944,\n",
              " 'video': 945,\n",
              " 'jump': 946,\n",
              " 'muslim': 947,\n",
              " 'weight': 948,\n",
              " 'hospital': 949,\n",
              " 'lives': 950,\n",
              " \"he'll\": 951,\n",
              " 'sent': 952,\n",
              " 'control': 953,\n",
              " 'football': 954,\n",
              " 'enjoy': 955,\n",
              " 'boat': 956,\n",
              " 'pool': 957,\n",
              " 'windows': 958,\n",
              " 'sense': 959,\n",
              " 'stole': 960,\n",
              " 'grow': 961,\n",
              " 'future': 962,\n",
              " 'wake': 963,\n",
              " 'anal': 964,\n",
              " 'train': 965,\n",
              " 'paint': 966,\n",
              " 'usually': 967,\n",
              " 'double': 968,\n",
              " 'waiting': 969,\n",
              " 'seems': 970,\n",
              " 'meant': 971,\n",
              " 'cows': 972,\n",
              " 'listen': 973,\n",
              " 'tea': 974,\n",
              " 'cock': 975,\n",
              " 'learn': 976,\n",
              " 'missing': 977,\n",
              " 'ride': 978,\n",
              " 'company': 979,\n",
              " 'pig': 980,\n",
              " 'movies': 981,\n",
              " 'pulled': 982,\n",
              " 'mirror': 983,\n",
              " 'moment': 984,\n",
              " 'wet': 985,\n",
              " 'changed': 986,\n",
              " 'n': 987,\n",
              " 'shut': 988,\n",
              " 'cute': 989,\n",
              " 'trouble': 990,\n",
              " 'threw': 991,\n",
              " 'early': 992,\n",
              " 'arm': 993,\n",
              " 'cup': 994,\n",
              " 'dr': 995,\n",
              " 'woke': 996,\n",
              " 'tweet': 997,\n",
              " 'deep': 998,\n",
              " 'soup': 999,\n",
              " 'north': 1000,\n",
              " ...}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_data = tokenizer.texts_to_sequences(data[\"Joke\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_len = 93"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_data_sequences = pad_sequences(input_data, maxlen=max_len, padding=\"post\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "70649"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) +1\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, LSTM, GRU, Reshape,Dropout,Input\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encoder\n",
        "incoder_in = Input(shape=(max_len,))\n",
        "incoder_embd = Embedding(vocab_size,256)(incoder_in)\n",
        "incoder_lstm = LSTM(512,return_state=True)\n",
        "incoder_out ,state_h,state_c= incoder_lstm(incoder_embd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Decoder\n",
        "dcoder_in = Input(shape=(max_len,))\n",
        "dcoder_embd = Embedding(vocab_size,256)(dcoder_in)\n",
        "dcoder_lstm = LSTM(512,return_state=True,return_sequences=True)\n",
        "dcoder_out ,_,_ = dcoder_lstm(dcoder_embd,initial_state=[state_h,state_c])\n",
        "\n",
        "# dense\n",
        "\n",
        "dcoder_dense = Dense(vocab_size,activation=\"softmax\")\n",
        "dcoder_out = dcoder_dense(dcoder_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
